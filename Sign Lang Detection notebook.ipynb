{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a713a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured image 1\n",
      "Captured image 2\n",
      "Captured image 3\n",
      "Captured image 4\n",
      "Captured image 5\n",
      "Captured image 6\n",
      "Captured image 7\n",
      "Captured image 8\n",
      "Captured image 9\n",
      "Captured image 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaptured image \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Wait for 0.5 seconds before capturing the next image\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Release the camera\u001b[39;00m\n\u001b[0;32m     41\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera\")\n",
    "    exit()\n",
    "\n",
    "# Create a folder to save the captured images\n",
    "import os\n",
    "if not os.path.exists(\"captured_images\"):\n",
    "    os.mkdir(\"captured_images\")\n",
    "\n",
    "# Capture and save 20 images\n",
    "for i in range(20):\n",
    "    # Capture a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Could not capture a frame\")\n",
    "        break\n",
    "\n",
    "    # Resize the frame to 70x70 pixels\n",
    "    frame = cv2.resize(frame, (70, 70))\n",
    "\n",
    "    # Generate a unique filename for each image\n",
    "    filename = f\"captured_images/image_{i + 1}.jpg\"\n",
    "\n",
    "    # Save the resized frame as an image\n",
    "    cv2.imwrite(filename, frame)\n",
    "\n",
    "    print(f\"Captured image {i + 1}\")\n",
    "\n",
    "    # Wait for 0.5 seconds before capturing the next image\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# Release the camera\n",
    "cap.release()\n",
    "\n",
    "print(\"Image capture complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6491845",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python opencv-python-headless numpy imutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e202c509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"deploy.prototxt\" in function 'cv::dnn::ReadProtoFromTextFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the pre-trained hand detection model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadNetFromCaffe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeploy.prototxt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmobilenet_v2.caffemodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize the camera\u001b[39;00m\n\u001b[0;32m     10\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"deploy.prototxt\" in function 'cv::dnn::ReadProtoFromTextFile'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "\n",
    "# Load the pre-trained hand detection model\n",
    "net = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'mobilenet_v2.caffemodel')\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera\")\n",
    "    exit()\n",
    "\n",
    "# Create a window to display the captured images\n",
    "cv2.namedWindow(\"Captured Images\")\n",
    "\n",
    "# Capture and display images with hand detection\n",
    "for i in range(20):\n",
    "    # Capture a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Could not capture a frame\")\n",
    "        break\n",
    "\n",
    "    # Resize the frame for faster processing (optional)\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "\n",
    "    # Get the frame dimensions\n",
    "    (h, w) = frame.shape[:2]\n",
    "\n",
    "    # Create a blob from the frame\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.2, (300, 300), (127.5, 127.5, 127.5), swapRB=True)\n",
    "\n",
    "    # Set the input to the neural network and perform a forward pass\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Loop over the detections\n",
    "    for j in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, j, 2]\n",
    "\n",
    "        # If the confidence is above a certain threshold (adjust as needed)\n",
    "        if confidence > 0.5:\n",
    "            # Calculate the bounding box coordinates\n",
    "            box = detections[0, 0, j, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(int)\n",
    "\n",
    "            # Draw the bounding box and label\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Hand {j + 1}\", (startX, startY - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame in the \"Captured Images\" window\n",
    "    cv2.imshow(\"Captured Images\", frame)\n",
    "\n",
    "    # Generate a unique filename for each image\n",
    "    filename = f\"captured_images/image_{i + 1}.jpg\"\n",
    "\n",
    "    # Save the frame as an image\n",
    "    cv2.imwrite(filename, frame)\n",
    "\n",
    "    print(f\"Captured image {i + 1}\")\n",
    "\n",
    "    # Wait for 0.5 seconds before capturing the next image\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # Check for a key press to exit\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  # Press Esc to exit\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dff0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Create a folder to save the captured images\n",
    "output_folder = \"hand_images\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize MediaPipe Hand module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Set up MediaPipe drawing utility\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize variables for image capture\n",
    "image_count = 0\n",
    "interval = 0.5  # Interval in seconds\n",
    "\n",
    "# Open a video capture device (0 for default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Hand\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Draw landmarks on the frame\n",
    "        for landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Capture and save an image every 0.5 seconds\n",
    "        current_time = time.time()\n",
    "        if current_time - interval >= image_count * interval:\n",
    "            image_count += 1\n",
    "            image_filename = os.path.join(output_folder, f\"hand_image_{image_count}.png\")\n",
    "            # Crop the image to 70x70 pixels\n",
    "            cropped_frame = frame[100:170, 100:170]\n",
    "            cv2.imwrite(image_filename, cropped_frame)\n",
    "            print(f\"Image {image_count} saved\")\n",
    "\n",
    "    # Display the frame with landmarks\n",
    "    cv2.imshow('Hand Detection', frame)\n",
    "\n",
    "    # Exit the loop when the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c34e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Create a folder to save the captured images\n",
    "output_folder = \"hand_images\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize MediaPipe Hand module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Set up MediaPipe drawing utility\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize variables for image capture\n",
    "image_count = 0\n",
    "interval = 1  # Interval in seconds\n",
    "\n",
    "# Open a video capture device (0 for default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Hand\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Draw landmarks on the frame\n",
    "        for landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Capture and save an image every 0.5 seconds\n",
    "        current_time = time.time()\n",
    "        if current_time - interval >= image_count * interval:\n",
    "            image_count += 1\n",
    "            image_filename = os.path.join(output_folder, f\"hand_image_{image_count}.png\")\n",
    "            # Crop the image to include the hand with some space around it (adjust as needed)\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            min_x, min_y, max_x, max_y = float('inf'), float('inf'), -float('inf'), -float('inf')\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                x, y, _ = frame.shape[1] * landmark.x, frame.shape[0] * landmark.y, landmark.z\n",
    "                min_x, min_y, max_x, max_y = min(min_x, x), min(min_y, y), max(max_x, x), max(max_y, y)\n",
    "            min_x, min_y, max_x, max_y = int(min_x), int(min_y), int(max_x), int(max_y)\n",
    "            margin = 50  # Adjust the margin as needed\n",
    "            min_x -= margin\n",
    "            min_y -= margin\n",
    "            max_x += margin\n",
    "            max_y += margin\n",
    "            cropped_frame = frame[min_y:max_y, min_x:max_x]\n",
    "            cv2.imwrite(image_filename, cropped_frame)\n",
    "            print(f\"Image {image_count} saved\")\n",
    "\n",
    "    # Display the frame with landmarks\n",
    "    cv2.imshow('Hand Detection', frame)\n",
    "\n",
    "    # Show the captured image being taken\n",
    "    if image_count > 0:\n",
    "        cv2.imshow('Captured Image', cropped_frame)\n",
    "\n",
    "    # Exit the loop when the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa86734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Create a folder to save the captured images\n",
    "output_folder = \"hand_images\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize MediaPipe Hand module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Initialize variables for image capture\n",
    "image_count = 0\n",
    "interval = 1  # Interval in seconds\n",
    "\n",
    "# Open a video capture device (0 for default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Hand\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Capture and save an image every 0.5 seconds\n",
    "        current_time = time.time()\n",
    "        if current_time - interval >= image_count * interval:\n",
    "            image_count += 1\n",
    "            image_filename = os.path.join(output_folder, f\"hand_image_{image_count}.png\")\n",
    "            # Crop the image to include the hand with some space around it (adjust as needed)\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            min_x, min_y, max_x, max_y = float('inf'), float('inf'), -float('inf'), -float('inf')\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                x, y, _ = frame.shape[1] * landmark.x, frame.shape[0] * landmark.y, landmark.z\n",
    "                min_x, min_y, max_x, max_y = min(min_x, x), min(min_y, y), max(max_x, x), max(max_y, y)\n",
    "            min_x, min_y, max_x, max_y = int(min_x), int(min_y), int(max_x), int(max_y)\n",
    "            margin = 50  # Adjust the margin as needed\n",
    "            min_x -= margin\n",
    "            min_y -= margin\n",
    "            max_x += margin\n",
    "            max_y += margin\n",
    "            cropped_frame = frame[min_y:max_y, min_x:max_x]\n",
    "            cv2.imwrite(image_filename, cropped_frame)\n",
    "            print(f\"Image {image_count} saved\")\n",
    "\n",
    "    # Display the frame without landmarks\n",
    "    cv2.imshow('Hand Detection', frame)\n",
    "\n",
    "    # Show the captured image being taken\n",
    "    if image_count > 0:\n",
    "        cv2.imshow('Captured Image', cropped_frame)\n",
    "\n",
    "    # Exit the loop when the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206383c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 saved\n",
      "Image 2 saved\n",
      "Image 3 saved\n",
      "Image 4 saved\n",
      "Image 5 saved\n",
      "Image 6 saved\n",
      "Image 7 saved\n",
      "Image 8 saved\n",
      "Image 9 saved\n",
      "Image 10 saved\n",
      "Image 11 saved\n",
      "Image 12 saved\n",
      "Image 13 saved\n",
      "Image 14 saved\n",
      "Image 15 saved\n",
      "Image 16 saved\n",
      "Image 17 saved\n",
      "Image 18 saved\n",
      "Image 19 saved\n",
      "Image 20 saved\n",
      "Image 21 saved\n",
      "Image 22 saved\n",
      "Image 23 saved\n",
      "Image 24 saved\n",
      "Image 25 saved\n",
      "Image 26 saved\n",
      "Image 27 saved\n",
      "Image 28 saved\n",
      "Image 29 saved\n",
      "Image 30 saved\n",
      "Image 31 saved\n",
      "Image 32 saved\n",
      "Image 33 saved\n",
      "Image 34 saved\n",
      "Image 35 saved\n",
      "Image 36 saved\n",
      "Image 37 saved\n",
      "Image 38 saved\n",
      "Image 39 saved\n",
      "Image 40 saved\n",
      "Image 41 saved\n",
      "Image 42 saved\n",
      "Image 43 saved\n",
      "Image 44 saved\n",
      "Image 45 saved\n",
      "Image 46 saved\n",
      "Image 47 saved\n",
      "Image 48 saved\n",
      "Image 49 saved\n",
      "Image 50 saved\n",
      "Image 51 saved\n",
      "Image 52 saved\n",
      "Image 53 saved\n",
      "Image 54 saved\n",
      "Image 55 saved\n",
      "Image 56 saved\n",
      "Image 57 saved\n",
      "Image 58 saved\n",
      "Image 59 saved\n",
      "Image 60 saved\n",
      "Image 61 saved\n",
      "Image 62 saved\n",
      "Image 63 saved\n",
      "Image 64 saved\n",
      "Image 65 saved\n",
      "Image 66 saved\n",
      "Image 67 saved\n",
      "Image 68 saved\n",
      "Image 69 saved\n",
      "Image 70 saved\n",
      "Image 71 saved\n",
      "Image 72 saved\n",
      "Image 73 saved\n",
      "Image 74 saved\n",
      "Image 75 saved\n",
      "Image 76 saved\n",
      "Image 77 saved\n",
      "Image 78 saved\n",
      "Image 79 saved\n",
      "Image 80 saved\n",
      "Image 81 saved\n",
      "Image 82 saved\n",
      "Image 83 saved\n",
      "Image 84 saved\n",
      "Image 85 saved\n",
      "Image 86 saved\n",
      "Image 87 saved\n",
      "Image 88 saved\n",
      "Image 89 saved\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Create a folder to save the captured images\n",
    "output_folder = \"Fx_newhand_images\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize MediaPipe Hand module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Initialize variables for image capture\n",
    "image_count = 0\n",
    "interval = 2  # Interval in seconds\n",
    "\n",
    "# Desired size for captured images\n",
    "desired_size = (70, 70)\n",
    "\n",
    "# Open a video capture device (0 for default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Hand\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Capture and save an image every 0.5 seconds\n",
    "        current_time = time.time()\n",
    "        if current_time - interval >= image_count * interval:\n",
    "            image_count += 1\n",
    "            image_filename = os.path.join(output_folder, f\"hand_image_{image_count}.png\")\n",
    "            # Crop the image to include the hand with some space around it (adjust as needed)\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            min_x, min_y, max_x, max_y = float('inf'), float('inf'), -float('inf'), -float('inf')\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                x, y, _ = frame.shape[1] * landmark.x, frame.shape[0] * landmark.y, landmark.z\n",
    "                min_x, min_y, max_x, max_y = min(min_x, x), min(min_y, y), max(max_x, x), max(max_y, y)\n",
    "            min_x, min_y, max_x, max_y = int(min_x), int(min_y), int(max_x), int(max_y)\n",
    "            margin = 50  # Adjust the margin as needed\n",
    "            min_x -= margin\n",
    "            min_y -= margin\n",
    "            max_x += margin\n",
    "            max_y += margin\n",
    "            cropped_frame = frame[min_y:max_y, min_x:max_x]\n",
    "            \n",
    "            # Resize the image to the desired size (70x70 pixels)\n",
    "            cropped_frame = cv2.resize(cropped_frame, desired_size)\n",
    "            \n",
    "            cv2.imwrite(image_filename, cropped_frame)\n",
    "            print(f\"Image {image_count} saved\")\n",
    "\n",
    "    # Display the frame without landmarks\n",
    "    cv2.imshow('Hand Detection', frame)\n",
    "\n",
    "    # Show the captured image being taken\n",
    "    if image_count > 0:\n",
    "        cv2.imshow('Captured Image', cropped_frame)\n",
    "\n",
    "    # Exit the loop when the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9042e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder containing the captured hand images\n",
    "image_folder = \"B_newhand_images\"\n",
    "\n",
    "# Target label for all the images\n",
    "target_label = 'B'\n",
    "\n",
    "# Initialize an empty list to store image data\n",
    "image_data = []\n",
    "\n",
    "# Iterate through the image files in the folder\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        # Read the image and flatten it to a 1D array\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = img.flatten()\n",
    "\n",
    "        # Append the target label as the first element\n",
    "        img_data = [target_label] + img_data.tolist()\n",
    "\n",
    "        # Append the image data to the list\n",
    "        image_data.append(img_data)\n",
    "\n",
    "# Create a DataFrame from the image data\n",
    "df = pd.DataFrame(image_data)\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file = \"hand_images.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_file, index=False, header=False)\n",
    "\n",
    "print(f\"CSV file '{csv_file}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d6b61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'hand_images_F.csv' updated successfully.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Existing CSV file containing images with target 'A'\n",
    "existing_csv_file = \"hand_images_E.csv\"\n",
    "\n",
    "# New folder containing images with target 'B'\n",
    "new_image_folder = \"F_newhand_images\"\n",
    "\n",
    "# Target label for the new images\n",
    "new_target_label = 'F'\n",
    "\n",
    "# Initialize an empty list to store image data\n",
    "new_image_data = []\n",
    "\n",
    "# Iterate through the new image files in the folder\n",
    "for filename in os.listdir(new_image_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        # Read the image and flatten it to a 1D array\n",
    "        image_path = os.path.join(new_image_folder, filename)\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = img.flatten()\n",
    "\n",
    "        # Append the new target label as the first element\n",
    "        img_data = [new_target_label] + img_data.tolist()\n",
    "\n",
    "        # Append the new image data to the list\n",
    "        new_image_data.append(img_data)\n",
    "\n",
    "# Load the existing CSV file into a DataFrame\n",
    "existing_df = pd.read_csv(existing_csv_file, header=None)\n",
    "\n",
    "# Create a DataFrame from the new image data\n",
    "new_df = pd.DataFrame(new_image_data)\n",
    "\n",
    "# Concatenate the existing and new DataFrames\n",
    "combined_df = pd.concat([existing_df, new_df])\n",
    "\n",
    "# Define the updated CSV file path\n",
    "updated_csv_file = \"hand_images_F.csv\"\n",
    "\n",
    "# Save the updated DataFrame to the CSV file\n",
    "combined_df.to_csv(updated_csv_file, index=False, header=False)\n",
    "\n",
    "print(f\"CSV file '{updated_csv_file}' updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb9138a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load the CSV file containing the dataset (assuming you have already loaded the dataset)\n",
    "data = pd.read_csv('hand_images_F.csv')\n",
    "\n",
    "# Select a random row from the dataset\n",
    "random_index = random.randint(0, len(data) - 1)\n",
    "image_data = data.iloc[random_index, 1:].values  # Extract pixel values\n",
    "image_label = data.iloc[random_index, 0]  # Extract label (if needed)\n",
    "\n",
    "# Reshape the image data to 70x70 pixels\n",
    "image_data = image_data.reshape(70, 70).astype('uint8')\n",
    "\n",
    "# Display the image in grayscale\n",
    "cv2.imshow('Gray Image', image_data)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73490bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv('hand_images_F.csv')\n",
    "\n",
    "# Extract a grayscale image from the dataset (assuming it's the first row)\n",
    "image_data = data.iloc[1000, 1:].values\n",
    "image = np.array(image_data, dtype=np.uint8).reshape(70, 70)\n",
    "\n",
    "# Display the image in the output terminal\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')  # Turn off axis labels and ticks\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb3b26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "112/112 [==============================] - 10s 76ms/step - loss: 0.8316 - accuracy: 0.6798 - val_loss: 0.0951 - val_accuracy: 0.9764\n",
      "Epoch 2/20\n",
      "112/112 [==============================] - 8s 75ms/step - loss: 0.1387 - accuracy: 0.9570 - val_loss: 0.0507 - val_accuracy: 0.9832\n",
      "Epoch 3/20\n",
      "112/112 [==============================] - 8s 75ms/step - loss: 0.0771 - accuracy: 0.9719 - val_loss: 0.0145 - val_accuracy: 0.9944\n",
      "Epoch 4/20\n",
      "112/112 [==============================] - 8s 74ms/step - loss: 0.0542 - accuracy: 0.9826 - val_loss: 0.0094 - val_accuracy: 0.9989\n",
      "Epoch 5/20\n",
      "112/112 [==============================] - 8s 73ms/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: 0.0065 - val_accuracy: 0.9978\n",
      "Epoch 6/20\n",
      "112/112 [==============================] - 8s 74ms/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
      "Epoch 7/20\n",
      "112/112 [==============================] - 8s 74ms/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 0.0087 - val_accuracy: 0.9978\n",
      "Epoch 8/20\n",
      "112/112 [==============================] - 8s 75ms/step - loss: 0.0356 - accuracy: 0.9885 - val_loss: 0.0076 - val_accuracy: 0.9966\n",
      "Epoch 9/20\n",
      "112/112 [==============================] - 9s 77ms/step - loss: 0.0286 - accuracy: 0.9896 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "112/112 [==============================] - 9s 76ms/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.0034 - val_accuracy: 0.9989\n",
      "Epoch 11/20\n",
      "112/112 [==============================] - 9s 76ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0031 - val_accuracy: 0.9989\n",
      "Epoch 12/20\n",
      "112/112 [==============================] - 9s 78ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0030 - val_accuracy: 0.9989\n",
      "Epoch 13/20\n",
      "112/112 [==============================] - 9s 80ms/step - loss: 0.0258 - accuracy: 0.9907 - val_loss: 0.0020 - val_accuracy: 0.9989\n",
      "Epoch 14/20\n",
      "112/112 [==============================] - 9s 76ms/step - loss: 0.0168 - accuracy: 0.9935 - val_loss: 0.0024 - val_accuracy: 0.9989\n",
      "Epoch 15/20\n",
      "112/112 [==============================] - 9s 76ms/step - loss: 0.0130 - accuracy: 0.9947 - val_loss: 0.0023 - val_accuracy: 0.9989\n",
      "Epoch 16/20\n",
      "112/112 [==============================] - 9s 77ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.0023 - val_accuracy: 0.9989\n",
      "Epoch 17/20\n",
      "112/112 [==============================] - 8s 75ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0037 - val_accuracy: 0.9989\n",
      "Epoch 18/20\n",
      "112/112 [==============================] - 8s 75ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0042 - val_accuracy: 0.9989\n",
      "Epoch 19/20\n",
      "112/112 [==============================] - 8s 75ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.0048 - val_accuracy: 0.9989\n",
      "Epoch 20/20\n",
      "112/112 [==============================] - 8s 75ms/step - loss: 0.0086 - accuracy: 0.9966 - val_loss: 0.0027 - val_accuracy: 0.9989\n",
      " 4/28 [===>..........................] - ETA: 0s - loss: 6.2932e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.9989\n",
      "Validation accuracy: 0.9988776445388794\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "data = pd.read_csv('hand_images_F.csv')\n",
    "\n",
    "data = shuffle(data, random_state=42)\n",
    "\n",
    "X = data.iloc[:, 1:].values\n",
    "y = data.iloc[:, 0].values\n",
    "\n",
    "X = X / 255.0\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "\n",
    "\n",
    "X = X.reshape(-1, 70, 70, 1)\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(70, 70, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(y.shape[1], activation='softmax')  # Number of classes for sign language digits\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=20,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "\n",
    "model.save('sign_language_model.h5')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_val, y_val)\n",
    "print(\"Validation accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4ead55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model('sign_language_model.h5')\n",
    "\n",
    "\n",
    "alphabet_symbols = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    \n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    \n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "           \n",
    "            height, width, _ = frame.shape\n",
    "            landmarks = [(int(l.x * width), int(l.y * height)) for l in hand_landmarks.landmark]\n",
    "\n",
    "        \n",
    "            padding = 30  # Adjust the padding as needed\n",
    "            min_x = max(0, min(landmarks, key=lambda p: p[0])[0] - padding)\n",
    "            max_x = min(width, max(landmarks, key=lambda p: p[0])[0] + padding)\n",
    "            min_y = max(0, min(landmarks, key=lambda p: p[1])[1] - padding)\n",
    "            max_y = min(height, max(landmarks, key=lambda p: p[1])[1] + padding)\n",
    "\n",
    "           \n",
    "            if max_x > min_x and max_y > min_y:\n",
    "                \n",
    "                cropped_hand = frame[min_y:max_y, min_x:max_x]\n",
    "\n",
    "               \n",
    "                gray_hand = cv2.cvtColor(cropped_hand, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "              \n",
    "                resized_hand = cv2.resize(gray_hand, (70, 70))\n",
    "                normalized_hand = resized_hand / 255.0\n",
    "                input_data = normalized_hand.reshape(1, 70, 70, 1)\n",
    "\n",
    "               \n",
    "                prediction = model.predict(input_data)\n",
    "                predicted_label = np.argmax(prediction)\n",
    "                predicted_symbol = alphabet_symbols[predicted_label]\n",
    "\n",
    "               \n",
    "                cv2.putText(frame, f'Predicted: {predicted_symbol}', (10, 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "          \n",
    "                cv2.imshow('Cropped Hand', normalized_hand)\n",
    "\n",
    "    \n",
    "    cv2.imshow('Camera and Prediction', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6274a314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e46a4e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the CSV dataset:\n",
      "      A  109  107  106  103  102  102.1  109.1  111  105  ...  109.69  113.79  \\\n",
      "0     A   78   78   83   81   78     80     84   79   83  ...     104      96   \n",
      "1     A   79   79   83   83   80     78     84   83   80  ...     104      96   \n",
      "2     A   76   82   86   86   78     89     92   91   89  ...      98      93   \n",
      "3     A   90   92   91   90   90     90     86   93   90  ...      95      83   \n",
      "4     A   84   83   90   82   85     85     87   90   82  ...      94      83   \n",
      "...  ..  ...  ...  ...  ...  ...    ...    ...  ...  ...  ...     ...     ...   \n",
      "4446  F  108  108  112  112   99    103    108  114  112  ...     221     217   \n",
      "4447  F  110  114  117  112  114    118    113  113  104  ...     223     219   \n",
      "4448  F  110  114  111  109  107    100    107  113  111  ...     215     218   \n",
      "4449  F  113  116  112  116  108    103    114  106  111  ...     216     214   \n",
      "4450  F  116  116  115  115  110    112    117  114  115  ...     215     215   \n",
      "\n",
      "      117.62  130.12  131.13  127.28  132.18  133.20  143.7  145.18  \n",
      "0         87      78      85      90      87      90     82      84  \n",
      "1         87      78      85      90      87      90     81      84  \n",
      "2         84      89      90      89      93      93     89      85  \n",
      "3         82      89      87      89      90      97     91      84  \n",
      "4         79      91      96      88      91      91     90      84  \n",
      "...      ...     ...     ...     ...     ...     ...    ...     ...  \n",
      "4446     217     215     214     215     209     202    183     159  \n",
      "4447     218     215     212     219     208     206    191     159  \n",
      "4448     221     209     215     215     212     203    183     152  \n",
      "4449     217     214     213     217     212     209    182     157  \n",
      "4450     216     212     212     213     210     204    186     162  \n",
      "\n",
      "[4451 rows x 4901 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_dataset.csv' with the path to your CSV file\n",
    "csv_file_path = 'hand_images_F.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Contents of the CSV dataset:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c3acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
